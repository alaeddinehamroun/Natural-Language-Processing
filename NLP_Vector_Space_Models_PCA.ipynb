{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Vector_Space_Models_PCA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAIFDpNbiBXuceBs4Bgq22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alaeddinehamroun/Natural-Language-Processing/blob/main/NLP_Vector_Space_Models_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the real world, you can always load the trained word vectors, and you will almost never have to train them from scratch."
      ],
      "metadata": {
        "id": "rNvP67I_iB5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 Predict the Countries from Capitals\n"
      ],
      "metadata": {
        "id": "D_SLDTBAiR74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Importing the data"
      ],
      "metadata": {
        "id": "NmT3fjlgiWhK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UZgQFwuZhyM6"
      },
      "outputs": [],
      "source": [
        "# Run this cell to import packages.\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectors(embeddings, words):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        embeddings: a word \n",
        "        fr_embeddings:\n",
        "        words: a list of words\n",
        "    Output: \n",
        "        X: a matrix where the rows are the embeddings corresponding to the rows on the list\n",
        "        \n",
        "    \"\"\"\n",
        "    m = len(words)\n",
        "    X = np.zeros((1, 300))\n",
        "    for word in words:\n",
        "        english = word\n",
        "        eng_emb = embeddings[english]\n",
        "        X = np.row_stack((X, eng_emb))\n",
        "    X = X[1:,:]\n",
        "    return X"
      ],
      "metadata": {
        "id": "12jX42hgiukF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import requests\n",
        "url=\"https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/Week%203/capitals.txt\"\n",
        "s=requests.get(url).content\n"
      ],
      "metadata": {
        "id": "De59v2BajwSD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(io.StringIO(s.decode('utf-8')), delimiter=' ')\n",
        "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
        "\n",
        "# print first five elements in the DataFrame\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pWJ2G6fJjHvY",
        "outputId": "d2b26598-9653-4893-9974-2af8b07a79f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    city1 country1    city2     country2\n",
              "0  Athens   Greece  Bangkok     Thailand\n",
              "1  Athens   Greece  Beijing        China\n",
              "2  Athens   Greece   Berlin      Germany\n",
              "3  Athens   Greece     Bern  Switzerland\n",
              "4  Athens   Greece    Cairo        Egypt"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41f00019-4be8-4c58-92e7-373009c51e72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city1</th>\n",
              "      <th>country1</th>\n",
              "      <th>city2</th>\n",
              "      <th>country2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bangkok</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bern</td>\n",
              "      <td>Switzerland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Cairo</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41f00019-4be8-4c58-92e7-373009c51e72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41f00019-4be8-4c58-92e7-373009c51e72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41f00019-4be8-4c58-92e7-373009c51e72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that because the original google news word embedding dataset is about 3.64 gigabytes, the workspace is not able to handle the full file set. So we've downloaded the full dataset, extracted a sample of the words that we're going to analyze in this assignment, and saved it in a pickle file called word_embeddings_capitals.p"
      ],
      "metadata": {
        "id": "29HB6LD5kdDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "nFdjuPNLkvBP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n",
        "f = open('capitals.txt', 'r').read()\n",
        "set_words = set(nltk.word_tokenize(f))\n",
        "select_words = words = ['king', 'queen', 'oil', 'gas', 'happy', 'sad', 'city', 'town', 'village', 'country', 'continent', 'petroleum', 'joyful']\n",
        "for w in select_words:\n",
        "    set_words.add(w)\n",
        "\n",
        "def get_word_embeddings(embeddings):\n",
        "\n",
        "    word_embeddings = {}\n",
        "    for word in embeddings.vocab:\n",
        "        if word in set_words:\n",
        "            word_embeddings[word] = embeddings[word]\n",
        "    return word_embeddings\n",
        "\n",
        "\n",
        "# Testing your function\n",
        "word_embeddings = get_word_embeddings(embeddings)\n",
        "print(len(word_embeddings))\n",
        "pickle.dump( word_embeddings, open( \"word_embeddings_subset.p\", \"wb\" ) )"
      ],
      "metadata": {
        "id": "ey3brhtUkdqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = pickle.load(open(\"word_embeddings_subset.p\", \"rb\"))\n",
        "len(word_embeddings)  # there should be 243 words that will be used in this assignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-MAOn_xk5pL",
        "outputId": "02e22295-539f-46b6-da04-889762ed3a80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dimension: {}\".format(word_embeddings['Spain'].shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rjCIrrxlFae",
        "outputId": "20eed798-7042-4114-f205-2e36c1fc8ac5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict relationships among words"
      ],
      "metadata": {
        "id": "Zykas0ralIFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The function will take as input three words.\n",
        "* The first two are related to each other.\n",
        "* It will predict a 4th word which is related to the third word in a similar manner as the two first words are related to each other.\n",
        "* As an example, \"Athens is to Greece as Bangkok is to __\"?\n",
        "* You will write a program that is capable of finding the fourth word.\n",
        "* We will give you a hint to show you how to compute this.\n"
      ],
      "metadata": {
        "id": "wVkKvdAZlXwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Cosine Similarity"
      ],
      "metadata": {
        "id": "8FzFsgxgEygD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(A, B):\n",
        "    '''\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        cos: numerical number representing the cosine similarity between A and B.\n",
        "    '''\n",
        "    \n",
        "    dot = np.dot(A,B)\n",
        "    norma = np.sqrt(np.dot(A,A))\n",
        "    normb = np.sqrt(np.dot(B,B))\n",
        "    cos = dot / (norma*normb)\n",
        "    return cos"
      ],
      "metadata": {
        "id": "I2Gsj6EmlMLO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "king = word_embeddings['king']\n",
        "queen = word_embeddings['queen']\n",
        "\n",
        "cosine_similarity(king, queen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO01VAEyFFF9",
        "outputId": "1197a0a3-c71a-4cdd-b7cf-9ba3d7884a39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510956"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Euclidean distance"
      ],
      "metadata": {
        "id": "u2LPo2h9FWfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean(A, B):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        d: numerical number representing the Euclidean distance between A and B.\n",
        "    \"\"\"\n",
        "\n",
        "    # euclidean distance\n",
        "\n",
        "    d = np.linalg.norm(A-B)\n",
        "\n",
        "    return d"
      ],
      "metadata": {
        "id": "sx-0I47WFbrz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "euclidean(king, queen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYIzpprxFlTK",
        "outputId": "db1a12af-bf2c-499c-d1ca-e8bb989ee7dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4796925"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Finding the country of each capital"
      ],
      "metadata": {
        "id": "12WSfEiIFnhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_country(city1, country1, city2, embeddings):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        city1: a string (the capital city of country1)\n",
        "        country1: a string (the country of capital1)\n",
        "        city2: a string (the capital city of country2)\n",
        "        embeddings: a dictionary where the keys are words and values are their embeddings\n",
        "    Output:\n",
        "        countries: a dictionary with the most likely country and its similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    # store the city1, country 1, and city 2 in a set called group\n",
        "    group = set((city1, country1, city2))\n",
        "\n",
        "    # get embeddings of city 1\n",
        "    city1_emb = word_embeddings[city1]\n",
        "\n",
        "    # get embedding of country 1\n",
        "    country1_emb = word_embeddings[country1]\n",
        "\n",
        "    # get embedding of city 2\n",
        "    city2_emb = word_embeddings[city2]\n",
        "\n",
        "    # get embedding of country 2 (it's a combination of the embeddings of country 1, city 1 and city 2)\n",
        "    # Remember: King - Man + Woman = Queen\n",
        "    vec = country1_emb - city1_emb + city2_emb\n",
        "\n",
        "    # Initialize the similarity to -1 (it will be replaced by a similarities that are closer to +1)\n",
        "    similarity = -1\n",
        "\n",
        "    # initialize country to an empty string\n",
        "    country = ''\n",
        "\n",
        "    # loop through all words in the embeddings dictionary\n",
        "    for word in embeddings.keys():\n",
        "\n",
        "        # first check that the word is not already in the 'group'\n",
        "        if word not in group:\n",
        "\n",
        "            # get the word embedding\n",
        "            word_emb = word_embeddings[word]\n",
        "\n",
        "            # calculate cosine similarity between embedding of country 2 and the word in the embeddings dictionary\n",
        "            cur_similarity = cosine_similarity(vec,word_emb)\n",
        "\n",
        "            # if the cosine similarity is more similar than the previously best similarity...\n",
        "            if cur_similarity > similarity:\n",
        "\n",
        "                # update the similarity to the new, better similarity\n",
        "                similarity = cur_similarity\n",
        "\n",
        "                # store the country as a tuple, which contains the word and the similarity\n",
        "                country = (word, similarity)\n",
        "    return country"
      ],
      "metadata": {
        "id": "-GELgkQSFray"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_country('Athens', 'Greece', 'Cairo', word_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx7jAH2-F-B_",
        "outputId": "95da860d-f4ca-48a6-edb9-ed82706915ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Egypt', 0.7626821)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Model Accuracy"
      ],
      "metadata": {
        "id": "ITcrVunJGAyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(word_embeddings, data):\n",
        "    '''\n",
        "    Input:\n",
        "        word_embeddings: a dictionary where the key is a word and the value is its embedding\n",
        "        data: a pandas dataframe containing all the country and capital city pairs\n",
        "    \n",
        "    Output:\n",
        "        accuracy: the accuracy of the model\n",
        "    '''\n",
        "\n",
        "    # initialize num correct to zero\n",
        "    num_correct = 0\n",
        "\n",
        "    # loop through the rows of the dataframe\n",
        "    for i, row in data.iterrows():\n",
        "\n",
        "        # get city1\n",
        "        city1 = row['city1']\n",
        "\n",
        "        # get country1\n",
        "        country1 = row['country1']\n",
        "\n",
        "        # get city2\n",
        "        city2 =  row['city2']\n",
        "\n",
        "        # get country2\n",
        "        country2 = row['country2']\n",
        "\n",
        "        # use get_country to find the predicted country2\n",
        "        predicted_country2, _ = get_country(city1,country1,city2,word_embeddings)\n",
        "\n",
        "        # if the predicted country2 is the same as the actual country2...\n",
        "        if predicted_country2 == country2:\n",
        "            # increment the number of correct by 1\n",
        "            num_correct += 1\n",
        "\n",
        "    # get the number of rows in the data dataframe (length of dataframe)\n",
        "    m = len(data)\n",
        "\n",
        "    # calculate the accuracy by dividing the number correct by m\n",
        "    accuracy = num_correct/m\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "oFgQ9BQqGE5Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = get_accuracy(word_embeddings, data)\n",
        "print(f\"Accuracy is {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5dgbvCJGOE7",
        "outputId": "218a63f3-61ee-47ff-d6dc-bcc9162e21c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Plotting the vectors using PCA"
      ],
      "metadata": {
        "id": "nhNJE9XaGeMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " As we saw, we are working in a 300-dimensional space in this case. Although from a computational perspective we were able to perform a good job, it is impossible to visualize results in such high dimensional spaces.\n",
        "\n",
        "\n",
        " You can think of PCA as a method that projects our vectors in a space of reduced dimension, while keeping the maximum information about the original vectors in their reduced counterparts. In this case, by maximum infomation we mean that the Euclidean distance between the original vectors and their projected siblings is minimal. Hence vectors that were originally close in the embeddings dictionary, will produce lower dimensional vectors that are still close to each other."
      ],
      "metadata": {
        "id": "tcvDeJRoGvBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps to compute PCA are as follows:\n",
        "\n",
        "\n",
        "1. Mean normalize the data\n",
        "2. Compute the covariance matrix of your data\n",
        "3. Compute the eigenvectors and the eigenvalues of your covariance matrix\n",
        "\n",
        "4. Multiply the first K eigenvectors by your normalized data. \n"
      ],
      "metadata": {
        "id": "G3GJpxJpG9gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pca(X, n_components=2):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        X: of dimension (m,n) where each row corresponds to a word vector\n",
        "        n_components: Number of components you want to keep.\n",
        "    Output:\n",
        "        X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
        "    \"\"\"\n",
        "\n",
        "    # mean center the data\n",
        "    X_demeaned = X - np.mean(X,axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix, UPLO='L')\n",
        "\n",
        "    # sort eigenvalue in increasing order (get the indices from the sort)\n",
        "    idx_sorted = np.argsort(eigen_vals)\n",
        "    \n",
        "    # reverse the order so that it's from highest to lowest.\n",
        "    idx_sorted_decreasing = idx_sorted[::-1]\n",
        "\n",
        "    # sort the eigen values by idx_sorted_decreasing\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\n",
        "\n",
        "    # sort eigenvectors using the idx_sorted_decreasing indices\n",
        "    eigen_vecs_sorted = eigen_vecs[:,idx_sorted_decreasing]\n",
        "\n",
        "    # select the first n eigenvectors (n is desired dimension\n",
        "    # of rescaled data array, or dims_rescaled_data)\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:,0:n_components]\n",
        "\n",
        "    # transform the data by multiplying the transpose of the eigenvectors \n",
        "    # with the transpose of the de-meaned data\n",
        "    # Then take the transpose of that product.\n",
        "    X_reduced = np.dot(eigen_vecs_subset.transpose(),X_demeaned.transpose()).transpose()\n",
        "\n",
        "    return X_reduced"
      ],
      "metadata": {
        "id": "U_zu9iGEGdEQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "X = np.random.rand(3, 10)\n",
        "X_reduced = compute_pca(X, n_components=2)\n",
        "print(\"Your original matrix was \" + str(X.shape) + \" and it became:\")\n",
        "print(X_reduced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4VSpELFHVMw",
        "outputId": "d0f609b8-1833-4b7b-ccc2-4dc854017c7c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your original matrix was (3, 10) and it became:\n",
            "[[ 0.43437323  0.49820384]\n",
            " [ 0.42077249 -0.50351448]\n",
            " [-0.85514571  0.00531064]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['oil', 'gas', 'happy', 'sad', 'city', 'town',\n",
        "         'village', 'country', 'continent', 'petroleum', 'joyful']\n",
        "\n",
        "# given a list of words and the embeddings, it returns a matrix with all the embeddings\n",
        "X = get_vectors(word_embeddings, words)\n",
        "\n",
        "print('You have 11 words each of 300 dimensions thus X.shape is:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW8TAmP1HZY3",
        "outputId": "1964a15b-a7ae-4d2a-c27e-b38c866236e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 11 words each of 300 dimensions thus X.shape is: (11, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = compute_pca(X, 2)\n",
        "plt.scatter(result[:, 0], result[:, 1])\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(result[i, 0] - 0.05, result[i, 1] + 0.1))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "tZA4CqNrHcup",
        "outputId": "cd70c23a-a594-4605-c95e-0b092fdc4abe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word vectors for 'gas', 'oil' and 'petroleum' appear related to each other, because their vectors are close to each other. Similarly, 'sad', 'joyful' and 'happy' all express emotions, and are also near each other."
      ],
      "metadata": {
        "id": "AedLZpuKHhU7"
      }
    }
  ]
}